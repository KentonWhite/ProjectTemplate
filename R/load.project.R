load.project <- function()
{
  cat('Loading project configuration\n')
  library('yaml')
  assign('config',
         yaml.load_file(file.path('config', 'global.yaml')),
         envir = .GlobalEnv)

  cat('Autoloading utility functions\n')
  source('lib/utilities.R')

  if (config[['load_libraries']] == 'on')
  {
    cat('Autoloading libraries\n')
    for (library.to.load in config[['libraries']])
    {
      cat(paste(' Loading library:', library.to.load, '\n'))
      library(library.to.load, character.only = TRUE)
    }
  }

  cat('Autoloading data\n')
  # Supported file extensions:
  #
  # .csv: CSV files that use a comma separator.
  # .csv.bz2: CSV files that use a comma separator and are compressed using bzip2.
  # .csv.zip: CSV files that use a comma separator and are compressed using zip.
  # .csv.gz: CSV files that use a comma separator and are compressed using gzip.
  # .tsv: CSV files that use a tab separator.
  # .tsv.bz2: CSV files that use a tab separator and are compressed using bzip2.
  # .tsv.zip: CSV files that use a tab separator and are compressed using zip.
  # .tsv.gz: CSV files that use a tab separator and are compressed using gzip.
  # .wsv: CSV files that use an arbitrary whitespace separator.
  # .wsv.bz2: CSV files that use an arbitrary whitespace separator and are compressed using bzip2.
  # .wsv.zip: CSV files that use an arbitrary whitespace separator and are compressed using zip.
  # .wsv.gz: CSV files that use an arbitrary whitespace separator and are compressed using gzip.
  # .RData: .RData binary files produced by save().
  # .rda: .RData binary files produced by save().
  # .url: A YAML file that contains an HTTP URL and a separator specification for a remote dataset.
  # .sql: A YAML file that contains database connection information for a MySQL database.
  # .sav: Binary file format generated by SPSS.
  # .dta: Binary file format generated by Stata.

  # Current data reader functions.
  CSVReader <- function(data.file, filename, variable.name)
  {
    assign(variable.name,
           read.csv(filename,
                    header = TRUE,
                    sep = ','),
           envir = .GlobalEnv)
  }

  TSVReader <- function(data.file, filename, variable.name)
  {
    assign(variable.name,
           read.csv(filename,
                    header = TRUE,
                    sep = '\t'),
           envir = .GlobalEnv)
  }

  WSVReader <- function(data.file, filename, variable.name)
  {
    assign(variable.name,
           read.csv(filename,
                    header = TRUE,
                    sep = ' '),
           envir = .GlobalEnv)
  }

  RDataReader <- function(data.file, filename, variable.name)
  {
    load(filename, envir = .GlobalEnv)
  }

  URLReader <- function(data.file, filename, variable.name)
  {
    # A .url file contains YAML describing the data source.
    # An example file is shown below.
    #
    # url: "http://www.johnmyleswhite.com/ProjectTemplate/sample_data.csv"
    # separator: ","

    url.info <- yaml.load_file(filename)

    assign(variable.name,
           read.csv(url.info[['url']],
                    header = TRUE,
                    sep = url.info[['separator']]),
           envir = .GlobalEnv)
  }

  SQLReader <- function(data.file, filename, variable.name)
  {
    # A .sql file contains YAML describing the data source.
    # Two example files are shown below.
    #
    # type: mysql
    # user: sample_user
    # password: sample_password
    # host: localhost
    # dbname: sample_database
    # table: sample_table
    #
    # type: sqlite
    # dbname: /path/to/sample_database
    # table: sample_table
    #
    # type: sqlite
    # dbname: /path/to/sample_database
    # query: SELECT * FROM users WHERE user_active == 1
    #
    
    database.info <- yaml.load_file(filename)

    if (! (database.info[['type']] %in% c('mysql', 'sqlite')))
    {
      warning('Only databases reachable through RMySQL and RSQLite
               are currently supported.')
      assign(variable.name,
             NULL,
             envir = .GlobalEnv)
      return()
    }

    if (database.info[['type']] == 'mysql')
    {
      library('RMySQL')
      mysql.driver <- dbDriver("MySQL")

      connection <- dbConnect(mysql.driver,
                              user = database.info[['user']],
                              password = database.info[['password']],
                              host = database.info[['host']],
                              dbname = database.info[['dbname']])
    }

    if (database.info[['type']] == 'sqlite')
    {
      library('RSQLite')
      sqlite.driver <- dbDriver("SQLite")

      connection <- dbConnect(sqlite.driver,
                              dbname = database.info[['dbname']])
    }

    # Added support for queries.
    # User should specify either a table name or a query to execute, but not both.
    table <- database.info[['table']]
    query <- database.info[['query']]
    
    # If both a table and a query are specified, favor the query.
    if (!is.null(table) & !is.null(query))
    {
    		warning(paste("'query' parameter in ",
    		              filename,
    		              " overrides 'table' parameter.",
    		              sep = ''))
    		table <- NULL
    }
    
    # If table is specified, read the whole table.
    # Othwrwise, execute the specified query.
    if (!is.null(table))
    {
      if (dbExistsTable(connection, table))
    	{
        data.parcel <- dbReadTable(connection,
    	                             table,
    	                             row.names = NULL)
    	  
    	  assign(variable.name,
    	         data.parcel,
    	         envir = .GlobalEnv)
    	}
    	else
    	{
    	  warning(paste('Table not found:', table))
    	  return()
    	}
    }
    else
    {
      data.parcel <- try(dbGetQuery(connection, query))
    	err <- dbGetException(connection)
      
    	if (class(data.parcel) == 'data.frame' & err$errorNum == 0)
    	{
    		assign(variable.name,
    					 data.parcel,
    					 envir = .GlobalEnv)
    	}
    	else
    	{
    		warning(paste("Error loading '",
    		              variable.name,
    		              "' with query '",
    		              query,
    							    "'\n    '",
    							    err$errorNum,
    							    "-",
    							    err$errorMsg,
    							    "'",
    							    sep = ''))
    		return()
    	}
    }

    # If the table exists but is empty, do not create a variable.
    # Or if the query returned no results, do not create a variable.
    if (nrow(data.parcel) == 0)
    {
      assign(variable.name,
             NULL,
             envir = .GlobalEnv)
      return()
    }

    # Disconnect from database resources. Warn if failure.
    disconnect.success <- dbDisconnect(connection)

    if (! disconnect.success)
    {
      warning(paste('Unable to disconnect from database:',
                    database.info[['dbname']]))
    }
  }

  SPSSReader <- function(data.file, filename, variable.name)
  {
    library('foreign')

    assign(variable.name,
           read.spss(filename),
           envir = .GlobalEnv)
  }

  StataReader <- function(data.file, filename, variable.name)
  {
    library('foreign')

    assign(variable.name,
           read.dta(filename),
           envir = .GlobalEnv)
  }

  XLSXReader <- function(data.file, filename, workbook.name)
  {
    library('xlsx')
    
    wb <- loadWorkbook(filename)
    sheets <- getSheets(wb)

    for (sheet.name in names(sheets))
    {
      variable.name <- paste(workbook.name, clean.variable.name(sheet.name), sep = ".")
      assign(variable.name,
             read.xlsx(filename,
                       sheetName = sheet.name,
                       header = TRUE),
             envir = .GlobalEnv)
    }
  }

  # Use a list to map file extension detection regular expressions to the
  # appropriate reader functions.
  extensions.dispatch.table <- list("\\.csv$" = CSVReader,
                                    "\\.csv.bz2$" = CSVReader,
                                    "\\.csv.zip$" = CSVReader,
                                    "\\.csv.gz$" = CSVReader,
                                    "\\.tsv$" = TSVReader,
                                    "\\.tsv.bz2$" = TSVReader,
                                    "\\.tsv.zip$" = TSVReader,
                                    "\\.tsv.gz$" = TSVReader,
                                    "\\.wsv$" = WSVReader,
                                    "\\.wsv.bz2$" = WSVReader,
                                    "\\.wsv.zip$" = WSVReader,
                                    "\\.wsv.gz$" = WSVReader,
                                    "\\.Rdata$" = RDataReader,
                                    "\\.rda$" = RDataReader,
                                    "\\.url$" = URLReader,
                                    "\\.sql$" = SQLReader,
                                    "\\.xlsx$" = XLSXReader)

  # First, we load everything out of cache/.
  cache.files <- dir('cache')

  for (cache.file in cache.files)
  {
    for (extension in names(extensions.dispatch.table))
    {
      filename <- file.path('cache', cache.file)

      if (grepl(extension, cache.file, ignore.case = TRUE, perl = TRUE))
      {
        variable.name <- clean.variable.name(sub(extension,
                                                 '',
                                                 cache.file,
                                                 ignore.case = TRUE,
                                                 perl = TRUE))

        cat(paste(" Loading cached data set: ", variable.name, '\n', sep = ''))

        do.call(extensions.dispatch.table[[extension]],
                list(cache.file,
                     filename,
                     variable.name))

        break()
      }
    }
  }

  # Then we consider loading things from data/.
  if (config[['data_loading']] == 'on')
  {
    data.files <- dir('data')

    for (data.file in data.files)
    {
      for (extension in names(extensions.dispatch.table))
      {
        filename <- file.path('data', data.file)

        if (grepl(extension, data.file, ignore.case = TRUE, perl = TRUE))
        {
          variable.name <- clean.variable.name(sub(extension,
                                                   '',
                                                   data.file,
                                                   ignore.case = TRUE,
                                                   perl = TRUE))

          # If this variable already exists in cache, don't load it from data.
          if (variable.name %in% ls(envir = .GlobalEnv))
          {
            next()
          }

          cat(paste(" Loading data set: ", variable.name, '\n', sep = ''))

          do.call(extensions.dispatch.table[[extension]],
                  list(data.file,
                       filename,
                       variable.name))

          break()
        }
      }
    }
  }

  if (config[['munging']] == 'on')
  {
    cat('Munging data\n')
    for (preprocessing.script in sort(dir('munge')))
    {
      cat(paste(' Running preprocessing script:', preprocessing.script, '\n'))
      source(file.path('munge', preprocessing.script))
    }
  }

  if (config[['logging']] == 'on')
  {
    cat('Initializing logger\n')
    library('log4r')
    # Need to think about why this didn't work in the naive way.
    # Something about how `level<-` works.
    logger <- create.logger()
    logfile(logger) <- file.path('logs', 'project.log')
    level(logger) <- log4r:::INFO
    assign('logger', logger, envir = .GlobalEnv)
  }
}
